name: Run Scraper

on:
  schedule:
    - cron: '0 */6 * * *' # Runs every 6 hours
  workflow_dispatch:      # Lets you click "Run Now" button

# ðŸ‘‡ THIS IS THE MAGIC PART YOU ARE MISSING
permissions:
  contents: write

jobs:
  scrape_and_save:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install cloudscraper beautifulsoup4 requests

      - name: Run Scraper Script
        run: python scraper.py

      # ðŸ‘‡ THIS PUSHES THE FILE BACK TO YOUR REPO
      - name: Save Results
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ðŸ¤– New Wallpapers Update"
          file_pattern: "featured.json"
          skip_dirty_check: false
